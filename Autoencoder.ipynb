{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc8a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statistics import mean\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a12ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586\n",
      "train size:97832\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./data/酒类股票收盘价.xlsx', header=1, index_col=0, skiprows=0)\n",
    "n = df.shape[1]\n",
    "keys = df.columns\n",
    "pairs = []\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        pair = df[[keys[i], keys[j]]].dropna()\n",
    "        S1 = pair[keys[i]]\n",
    "        S2 = pair[keys[j]]\n",
    "        result = coint(S1, S2)\n",
    "        pvalue = result[1]\n",
    "        if pvalue < 1:\n",
    "            pairs.append((keys[i], keys[j]))\n",
    "print(len(pairs))\n",
    "\n",
    "X_train = []\n",
    "for pair in pairs:\n",
    "    data = df[list(pair)]\n",
    "    ratios = data.iloc[:, 0]/data.iloc[:, 1]\n",
    "    ma1 = ratios.rolling(window=5, center=False).mean()\n",
    "    ma2 = ratios.rolling(window=60, center=False).mean()\n",
    "    std = ratios.rolling(window=60, center=False).std()\n",
    "    zscore = ((ma1 - ma2)/std).dropna()\n",
    "    \n",
    "    size = 90\n",
    "    X_train.extend([np.array(zscore.iloc[i:i+size].values) for i in range(0, len(zscore)-size, 5)])\n",
    "\n",
    "train_size = int(len(X_train) * 0.7)\n",
    "print('train size:%d' % train_size)\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "X_test = X_train[train_size:]\n",
    "X_train = X_train[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce12d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(90, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 8)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 90),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745ad485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50], loss:0.4509\n",
      "epoch [2/50], loss:0.1874\n",
      "epoch [3/50], loss:0.1327\n",
      "epoch [4/50], loss:0.1195\n",
      "epoch [5/50], loss:0.1028\n",
      "epoch [6/50], loss:0.0994\n",
      "epoch [7/50], loss:0.0986\n",
      "epoch [8/50], loss:0.0980\n",
      "epoch [9/50], loss:0.0970\n",
      "epoch [10/50], loss:0.0968\n",
      "epoch [10/50], test loss:0.0984\n",
      "epoch [11/50], loss:0.0962\n",
      "epoch [12/50], loss:0.0958\n",
      "epoch [13/50], loss:0.0959\n",
      "epoch [14/50], loss:0.0953\n",
      "epoch [15/50], loss:0.0962\n",
      "epoch [16/50], loss:0.0952\n",
      "epoch [17/50], loss:0.0954\n",
      "epoch [18/50], loss:0.0950\n",
      "epoch [19/50], loss:0.0951\n",
      "epoch [20/50], loss:0.0956\n",
      "epoch [20/50], test loss:0.1004\n",
      "epoch [21/50], loss:0.0949\n",
      "epoch [22/50], loss:0.0949\n",
      "epoch [23/50], loss:0.0950\n",
      "epoch [24/50], loss:0.0952\n",
      "epoch [25/50], loss:0.0949\n",
      "epoch [26/50], loss:0.0951\n",
      "epoch [27/50], loss:0.0949\n",
      "epoch [28/50], loss:0.0949\n",
      "epoch [29/50], loss:0.0950\n",
      "epoch [30/50], loss:0.0949\n",
      "epoch [30/50], test loss:0.0976\n",
      "epoch [31/50], loss:0.0953\n",
      "epoch [32/50], loss:0.0948\n",
      "epoch [33/50], loss:0.0952\n",
      "epoch [34/50], loss:0.0947\n",
      "epoch [35/50], loss:0.0952\n",
      "epoch [36/50], loss:0.0947\n",
      "epoch [37/50], loss:0.0948\n",
      "epoch [38/50], loss:0.0949\n",
      "epoch [39/50], loss:0.0948\n",
      "epoch [40/50], loss:0.0948\n",
      "epoch [40/50], test loss:0.0981\n",
      "epoch [41/50], loss:0.0948\n",
      "epoch [42/50], loss:0.0948\n",
      "epoch [43/50], loss:0.0947\n",
      "epoch [44/50], loss:0.0948\n",
      "epoch [45/50], loss:0.0947\n",
      "epoch [46/50], loss:0.0946\n",
      "epoch [47/50], loss:0.0944\n",
      "epoch [48/50], loss:0.0944\n",
      "epoch [49/50], loss:0.0940\n",
      "epoch [50/50], loss:0.0939\n",
      "epoch [50/50], test loss:0.0970\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        inputs = torch.tensor(X_train[i:i + batch_size],  dtype=torch.float, device=device)\n",
    "        inputs = torch.nan_to_num(inputs, posinf=20.0, neginf=-20.0)\n",
    "        outputs = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, mean(train_loss)))\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, X_test.shape[0], batch_size):\n",
    "                inputs = torch.tensor(X_test[i:i + batch_size],  dtype=torch.float, device=device)\n",
    "                inputs = torch.nan_to_num(inputs, posinf=20.0, neginf=-20.0)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                test_loss.append(loss.item())\n",
    "            \n",
    "        print('epoch [{}/{}], test loss:{:.4f}'.format(epoch + 1, num_epochs, mean(test_loss)))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bad1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
